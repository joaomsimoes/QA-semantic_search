{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Annotation Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prodigy.components.db import connect\n",
    "\n",
    "db = connect(db_id='mysql', db_settings= {\"user\": \"\",\n",
    "                                            \"password\": \"\",\n",
    "                                            \"host\": \"cryptobot.c0qod4rtiyaw.eu-central-1.rds.amazonaws.com\",\n",
    "                                            \"port\": 3306,\n",
    "                                            \"database\": \"annotations\"\n",
    "                                        })\n",
    "\n",
    "data = db.get_dataset(\"semanticsearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def checker(answer=None):\n",
    "    if answer == 'accept':\n",
    "        row['pos'].append(text)\n",
    "    elif answer == 'reject':\n",
    "        row['neg'].append(text)\n",
    "    else:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "108"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "bag = []\n",
    "corpus = []\n",
    "row = {'query': '', 'pos': [], 'neg': []}\n",
    "\n",
    "# Iterate all annotations from Prodigy and store all\n",
    "# pos and neg in a bag corresponding to a query\n",
    "for line in data:\n",
    "    query = line['label']\n",
    "    text = line['text']\n",
    "    answer = line['answer']\n",
    "\n",
    "    # for the first iteration\n",
    "    if row['query'] == '':\n",
    "        row['query'] = query\n",
    "        checker(answer)\n",
    "\n",
    "    # when there is a new query\n",
    "    elif query != row['query']:\n",
    "        bag.append(row)\n",
    "        row = {'query': query, 'pos': [], 'neg': []}\n",
    "        checker(answer)\n",
    "\n",
    "    # append pos and negs to the same query\n",
    "    else:\n",
    "        checker(answer)\n",
    "\n",
    "# for each query append only one pos and one neg\n",
    "# normally there is more neg than pos, for that reason\n",
    "# i decided to iterate over the negatives and append\n",
    "# random pos (not the best solution)\n",
    "for data in bag:\n",
    "    negatives = data['neg']\n",
    "    positives = data['pos']\n",
    "\n",
    "    for i, value in enumerate(range(len(negatives))):\n",
    "        try:\n",
    "            row = {'query': data['query'],\n",
    "                   'pos': random.choice(positives),\n",
    "                   'neg': negatives[i]}\n",
    "\n",
    "            corpus.append(row)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "random.shuffle(corpus)\n",
    "len(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "corpus_train = corpus[:75]\n",
    "corpus_test = corpus[75:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training SBERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "model = SentenceTransformer('./msmarco/msmarco-distilbert-dot-v5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using pytorch to load the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class ProdigyDataset(Dataset):\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        query = self.corpus[item]\n",
    "\n",
    "        query_text = query['query']\n",
    "        pos_text = query['pos']\n",
    "        neg_text = query['neg']\n",
    "\n",
    "        return InputExample(texts=[query_text, pos_text, neg_text])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_dataset = ProdigyDataset(corpus_train)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n",
    "\n",
    "#I use MultipleNegativesRankingLoss because I have a Positive passage and a hard Negative passage.\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_24348/2975520758.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m model.fit(train_objectives=[(train_dataloader, train_loss)],\n\u001B[0m\u001B[0;32m      2\u001B[0m           \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m           \u001B[0mwarmup_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1000\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m           \u001B[0muse_amp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m           \u001B[0mcheckpoint_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'./'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=5,\n",
    "          warmup_steps=1000,\n",
    "          use_amp=True,\n",
    "          checkpoint_path='./',\n",
    "          checkpoint_save_steps=200,\n",
    "          optimizer_params = {'lr': 2e-5}\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model.save('./saved_model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MSMarco"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.65"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "test_dataset = ProdigyDataset(corpus_test)\n",
    "evaluator = TripletEvaluator.from_input_examples(test_dataset, batch_size=8)\n",
    "\n",
    "model.evaluate(evaluator=evaluator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finetuned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.65"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "model_fine = SentenceTransformer('./saved_model')\n",
    "evaluator = TripletEvaluator.from_input_examples(test_dataset, batch_size=8)\n",
    "\n",
    "model_fine.evaluate(evaluator=evaluator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}